{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5JU8AHhPAtBT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras import layers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "file_name = 'ESC50.zip'\n",
        "\n",
        "# Check if the file is a valid ZIP file\n",
        "try:\n",
        "    with ZipFile(file_name, 'r') as zip:\n",
        "        print(zip.namelist())\n",
        "except Exception as e:\n",
        "    print(e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ilCX_WiDFVE",
        "outputId": "2bc18099-433d-4840-9e32-8aa19d1a69c4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File is not a zip file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to load an audio file and extract features\n",
        "def load_audio_file(file_path):\n",
        "    signal, sr = librosa.load(file_path, sr=None)\n",
        "    mfcc = librosa.feature.mfcc(signal, sr=sr)\n",
        "    return mfcc\n",
        "\n",
        "# Function to load a dataset\n",
        "def load_dataset(path):\n",
        "    files = []\n",
        "    labels = []\n",
        "\n",
        "    # Iterate over all files in the path\n",
        "    for filename in os.listdir(path):\n",
        "        if filename.endswith(\".wav\"):\n",
        "            # Extract the class label from the filename\n",
        "            class_label = filename.split(\"-\")[-1].replace(\".wav\", \"\")\n",
        "\n",
        "            # Load the audio file and extract features\n",
        "            mfcc = load_audio_file(os.path.join(path, filename))\n",
        "\n",
        "            files.append(mfcc)\n",
        "            labels.append(class_label)\n",
        "\n",
        "    return np.array(files), np.array(labels)\n",
        "\n",
        "# Load the ESC-50 dataset\n",
        "#ESC50_PATH = \"/path/to/ESC-50\"\n",
        "#X_noise, y_noise = load_dataset(ESC50_PATH)\n",
        "\n",
        "# Convert the ESC-50 dataset into a TensorFlow Dataset\n",
        "#noise_dataset = tf.data.Dataset.from_tensor_slices((X_noise, y_noise))\n",
        "\n",
        "# Load the LibriSpeech dataset\n",
        "voice_dataset = tfds.load('librispeech', split='train')\n",
        "\n",
        "# Preprocess the LibriSpeech dataset\n",
        "voice_dataset = voice_dataset.map(lambda x: load_audio_file(x['speech']))\n"
      ],
      "metadata": {
        "id": "h95YVQOACEOK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "outputId": "60202915-67dd-4285-fe9d-0f1ac765a792"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-07a87bb92865>\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Load the LibriSpeech dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mvoice_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'librispeech'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Preprocess the LibriSpeech dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/core/logging/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, function, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m       \u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/core/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, split, data_dir, batch_size, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001b[0m\n\u001b[1;32m    638\u001b[0m       \u001b[0mtry_gcs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m   )\n\u001b[0;32m--> 640\u001b[0;31m   \u001b[0m_download_and_prepare_builder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdbuilder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_and_prepare_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mas_dataset_kwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/core/load.py\u001b[0m in \u001b[0;36m_download_and_prepare_builder\u001b[0;34m(dbuilder, download, download_and_prepare_kwargs)\u001b[0m\n\u001b[1;32m    497\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m     \u001b[0mdownload_and_prepare_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_and_prepare_kwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m     \u001b[0mdbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_and_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdownload_and_prepare_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/core/logging/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, function, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m       \u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36mdownload_and_prepare\u001b[0;34m(self, download_dir, download_config, file_format)\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0mdirectory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_dir_root\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m     ):\n\u001b[0;32m--> 598\u001b[0;31m       raise IOError(\n\u001b[0m\u001b[1;32m    599\u001b[0m           \u001b[0;34m\"Not enough disk space. Needed: {} (download: {}, generated: {})\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           .format(\n",
            "\u001b[0;31mOSError\u001b[0m: Not enough disk space. Needed: 361.62 GiB (download: 57.14 GiB, generated: 304.47 GiB)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to create a model\n",
        "def create_model():\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    # Add convolutional layers\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(None, None, 1)))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    # Add dense layers\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dense(1))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create the models\n",
        "#noise_model = create_model()\n",
        "voice_model = create_model()\n"
      ],
      "metadata": {
        "id": "670HAdGCCKxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Compile the models\n",
        "noise_model.compile(optimizer='adam', loss='mse')\n",
        "voice_model.compile(optimizer='adam', loss='mse')\n"
      ],
      "metadata": {
        "id": "cT-mmfYnCPqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train the models\n",
        "noise_model.fit(noise_dataset.batch(32), epochs=10)\n",
        "voice_model.fit(voice_dataset.batch(32), epochs=10)\n"
      ],
      "metadata": {
        "id": "7dDQtzsJCSc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Save the models\n",
        "noise_model.save('noise_model.h5')\n",
        "voice_model.save('voice_model.h5')\n"
      ],
      "metadata": {
        "id": "qGV_l-XaCUdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluate the models\n",
        "noise_evaluation = noise_model.evaluate(noise_dataset.batch(32))\n",
        "voice_evaluation = voice_model.evaluate(voice_dataset.batch(32))\n",
        "\n",
        "print('Noise model evaluation:', noise_evaluation)\n",
        "print('Voice model evaluation:', voice_evaluation)\n"
      ],
      "metadata": {
        "id": "YfYlrTQ3CWfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load a new audio file for prediction\n",
        "new_audio_file = \"/path/to/new/audio/file.wav\"\n",
        "new_audio_mfcc = load_audio_file(new_audio_file)\n",
        "\n",
        "# Reshape the MFCCs to match the input shape of our model\n",
        "new_audio_mfcc = new_audio_mfcc.reshape(1, *new_audio_mfcc.shape, 1)\n",
        "\n",
        "# Make a prediction\n",
        "prediction = voice_model.predict(new_audio_mfcc)\n",
        "\n",
        "print('Prediction:', prediction)\n"
      ],
      "metadata": {
        "id": "9ieW8OkmCYrC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}